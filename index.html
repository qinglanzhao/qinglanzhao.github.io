<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Qinglan Zhao's Website</title>

  <!-- Latest compiled and minified CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"
        integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  <!-- Custom CSS -->
  <link href="sass/style.css" rel="stylesheet">  
  
  <link REL="SHORTCUT ICON" HREF="kiwi.png">
  
</head>


<!-- The #page-top ID is part of the scrolling feature - the data-spy and data-target are part of the built-in Bootstrap
scrollspy function -->

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

<!-- Navigation -->
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header page-scroll">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand page-scroll" href="#page-top">Qinglan Zhao</a>
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse navbar-ex1-collapse">
      <ul class="nav navbar-nav">
        <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
        <li class="hidden">
          <a class="page-scroll" href="#page-top"></a>
        </li>
        <li>
          <a class="page-scroll" href="#about">About</a>
        </li>
        <li>
          <a class="page-scroll" href="#publication">Publications</a>
        </li>
        <li>
          <a class="page-scroll" href="#more about">More about Me</a>
        </li>
      </ul>
    </div>
    <!-- /.navbar-collapse -->
  </div>
  <!-- /.container -->
</nav>

<!-- Section: Introduction -->
<section id="intro" class="section-intro">
  <div class="container">
    <div class="row">
      <div class="col-xs-6 col-xs-offset-3 my-info">
        <h1>Qinglan Zhao</h1>
        <p>
          <!-- Stanford Vision and Learning Lab<br> -->
		  PhD Candidate, The University of Queensland<br>
          Advisor: <a href="http://researchers.uq.edu.au/researcher/474">Prof. George Zhao</a> and <a href="http://researchers.uq.edu.au/researcher/138">Prof. Andrew K. Whittaker</a>
          <!-- The University of Queensland<br> -->
          qinglanangela.zhao@uq.edu.au<br>
          <a href="https://scholar.google.com.au/citations?user=EMHP0UsAAAAJ&hl=en">[Google Scholar]</a>
          <!-- <a href="https://github.com/d1ngn1gefe1">[Github]</a> -->
          <a href="intro/CV_Qinglan Zhao.pdf">[CV (updated on Dec 2018)]</a>
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Section: About -->
<section id="about" class="section-about">
  <div class="container">
    <div class="row">
      <h1 class="subtitle">About</h1>
    </div>

    <div class="row">
	<h3 class="text-left">Mission</h3>
      <p class="text-left">
        •	I am aiming to bridge the gap between fundamental sciences and novel applications. 
      </p>
      <p class="text-left">
        •	I am ambitious, young, creative and dedicated to the cutting-edge energy storage field.
      </p>
	  <p class="text-left">
        •	I am a lifelong learner and enthusiast in the world of science and technology.
      </p>
	  <p class="text-left">
        <!-- My current works focus on object detection and related medical applications. I'm now looking for internship. Please contact me if you have available positions. -->
      </p>
    </div>

	
    <div class="row">
      <h3 class="text-left">Education</h3>
      <div class="col-xs-4">
        <img src="about/UQlogo.png" class="img-fluid school-fig img-fluid">
        <p>Doctor of Philosophy, Chemical Engineeering<br>          
          The University of Queensland, World University Rankings:48th<br>
          2016.01 - Present (Degree expected by Sep 2019)
        </p>
      </div>
      <div class="col-xs-4">
        <img src="about/XTUlogo.png" class="img-fluid school-fig img-circle">
        <p>Master of Science, Chemistry<br>
          Xiangtan University, Chinese University Rankings: 106th<br>
          2012.09 - 2015.06
        </p>
      </div>
	   <div class="col-xs-4">
        <img src="about/XTUlogo.png" class="img-fluid school-fig img-circle">
        <p>Bachelor of Science, Pharmacy<br>
          Xiangtan University, Chinese University Rankings: 106th<br>
		  2008.09 - 2012.06
        </p>
      </div>
	  
	  
	      </div>
    <div class="row">
      <h3 class="text-left">Research Interests</h3>
      <p class="text-left">
        •	Flexible and stretchable electronics and energy devices
      </p>
	  <p class="text-left">
        •	Design and synthesis of organic molecules and polymers for sustainable energy storage and conversion systems
      </p>
	  <p class="text-left">
        •	Mechanism study of electrochemical reactions by a series of advanced characterizations with a combination of theoretical calculations
      </p>
	  <p class="text-left">
        </p>
    </div>
   
	
<!-- 	<div class="row">
      <h3 class="text-left">Industry</h3>
      <div class="col-xs-4">
        <img src="about/china-mobile-logo.png" class="img-fluid company-fig img-circle">
        <p>China Mobile<br>
          Research Intern<br>
          Summer 2014
        </p>
      </div>
    </div> -->
	
	<div class="row">
      <h3 class="text-left">Research Experience</h3>
      </p>
	  <p class="text-left">
        •	Project: Fundamental study of advanced polymer electrodes for novel sodium-ion energy storage systems, University of Queensland, supervised by George Zhao (ARC Australian Laureate Fellow) and Andrew K. Whittaker (ARC Australian Research Fellow)
      </p>
	  <p class="text-left">
		•	Project: Design and assembly of commercial batteries, Deakin University, supervised by Maria Forsyth (ARC Australian Laureate Fellow), Patrick Howlett and Robert Kerr
		</p>
	  <p class="text-left">
        •	Project: Advanced carbon materials for electrochemical energy conversion and storage, Xiangtan University, supervised by Xianyou Wang (the Scientific Chinese 2016 and the highly cited Chinese scholar since 2014)
      </p>
	  <p class="text-left">
		•	Project: Electrochemical sensing platform based on polymer biomimic membrane (team leader of the National Undergraduate Innovative Project), Xiangtan University, supervised by Junjie Fei
	  <p class="text-left">
        •	Teaching assistant in Physical Chemistry
      </p>
	  <p class="text-left">
		•	Equipment training: SEM (JOEL 6610, JOEL 7001F, JOEL 7800), TEM (HITACHI 7700, JOEL 2100), XPS (Kratos Axis Ultra), FTIR (Nicolet 5700), TG (DTG-60A), surface area and pore size analyzer (TriStar II 3020)
      </p>
	  <p class="text-left">
        </p>
    </div>

	
	<div class="row">
      <h3 class="text-left">Community Services</h3>
      </p>
	  <p class="text-left">
        •	Vice President, Graduate Student Union, Xiangtan University,                                    2013-2015
      </p>
	  <p class="text-left">  
		•	Executive President, Graduate Student Union, Xiangtan University,                               2012-2013
		</p>
	  <p class="text-left">
        •	Office Director, Student Union, Xiangtan University,                                            2009-2011
      </p>
	  <p class="text-left">
		•	Reporter and Editor, Sky31 Website, Xiangtan University,                                        2008-2010
	  <p class="text-left">
        </p>
    </div>
    
	
	<div class="row">
      <h3 class="text-left">Honours and Awards</h3>
         </p>
	  <p class="text-left">
        •	International Postgraduate Research Scholarship, 2016 (academic merit-based)
      </p>
	  <p class="text-left">  
		•	University of Queensland Centennial Scholarship, 2016 (academic merit-based)
		</p>
	  <p class="text-left">
        •	Outstanding Graduates of the State, 2015 (top 1 %)
      </p>
	  <p class="text-left">
		•	Principal Grant, 2015 (top 1 %)
	  </p>
	  <p class="text-left">
     	•	National Graduates Scholarship, 2014 (top 1 %)
      </p>
	  <p class="text-left">  
		•	Outstanding Postgraduate Student Leader, 2013 (top 5 %)
	  </p>
	  <p class="text-left">
        •	Outstanding Graduates Award, 2012 (top 5 %)
	   </p>
	  <p class="text-left">
		•	The First-prize Scholarship, 2011 (top 3 %)
		</p>
	  <p class="text-left">
        •	81 Millionaire’s Scholarship, 2011 (top 3 %)
      </p>
	  <p class="text-left">
		•	The Second-prize Scholarship, 2010 (top 5 %)
	  </p>
	  <p class="text-left">
        •	Hecheng Scholarship, 2010 (top 1 %)
      </p>
	  <p class="text-left">
		•	The Third-prize Scholarship, 2009 (top 10%)
	  <p class="text-left">
        </p>
    </div>
	
  </div>
</section>

<!-- Section: Publication-->
<section id="publication" class="section-publication">
  <div class="container">
    <div class="row">
      <h1 class="subtitle">Selected Publications</h1>
    </div>
	
    <div class="row">
      <!-- <h3 class="text-left">Computer Vision and Deep Learning</h3> -->
      <div class="row paper">
        <div class="col-xs-3">
          <img src="publications/fig_perceptibility_comparison.png" class="paper-fig img-responsive">
        </div>
        <div class="col-xs-9">
          <h4 class="text-left">Tailored polyimide-graphene nanocomposite as negative electrode and reduced graphene oxide as positive electrode for flexible hybrid sodium-ion capacitors</h4>
          <p class="text-left">
            <span class="label label-success">Composite electrode</span>
            <span class="label label-success">Flexible device</span>
            <span class="label label-success">Graphene</span>
			<span class="label label-success">Polyimide</span>
            <span class="label label-success">Sodium-ion capacitor</span>
			
<!--             <span class="label label-success">Learning Using Priviledged Information</span> -->
          </p>
          <p class="text-left"><strong>Siqi Yang</strong>, Arnold Wiliem, Shaokang Chen, Brian C. Lovell</p>
          <p class="text-left">ACS Appl. Mater. Inter., 2018, 10, 43730-43739.</p>
          <div class="text-left btns">
            <a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
               title="Abstract" data-content="This work shows that it is possible to fool/attack recent state-of-the-art face detectors which are based on the single-stage networks. Successfully attacking face detectors could be a serious malware vulnerability when deploying a smart surveillance system utilizing face detectors. In addition, for the privacy concern, it helps prevent faces being harvested and stored in the server. We show that existing adversarial perturbation methods are not effective to perform such an attack, especially when there are multiple faces in the input image. This is because the adversarial perturbation specifically generated for one face may disrupt the adversarial perturbation for another face. In this paper, we call this problem the Instance Perturbation Interference (IPI) problem. This IPI problem is addressed by studying the relationship between the deep neural network receptive field and the adversarial perturbation. Besides the single-stage face detector, we find that the IPI problem also exists on the first stage of the Faster-RCNN, the commonly used two-stage object detector. As such, we propose the Localized Instance Perturbation (LIP) that confines the adversarial perturbation inside the Effective Receptive Field (ERF) of a target to perform the attack. Experimental results show the LIP method massively outperforms existing adversarial perturbation generation methods -- often by a factor of 2 to 10."
            >Abstract</a>
            <a class="btn btn-default btn-xs" target="_blank" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Siqi_Yang_Using_LIP_to_ECCV_2018_paper.pdf">PDF</a>
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://alan.vision/eccv18_graph">Project</a> -->
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://siqi.vision/publications/eccv18_poster_Siqi_Yang_15_11_2018.pdf">Poster</a> -->
			<!-- <a class="btn btn-default btn-xs" target="_blank" href="https://www.youtube.com/watch?v=nJdG4ujAg1Q">Demo video</a> -->
          </div>
        </div>
      </div>
	  
	  <div class="row paper">
        <div class="col-xs-3">
          <img src="publications/cascadedrawing.jpg" class="paper-fig img-responsive">
        </div>
        <div class="col-xs-9">
          <h4 class="text-left">A hybrid sodium-ion capacitor with polyimide as anode and polyimide-derived carbon as cathode</h4>
          <p class="text-left">
            <span class="label label-success">Face Detection</span>
            <span class="label label-success">False Positive Analysis</span>
            <!-- <span class="label label-success">Object Detection</span> -->
<!--             <span class="label label-success">Learning Using Priviledged Information</span> -->
          </p>
          <p class="text-left"><strong>Siqi Yang</strong>, Arnold Wiliem, Brian C. Lovell</p>
          <p class="text-left">J. Power Sources, 2018, 396, 12-18.</p>
          <div class="text-left btns">
            <a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
               title="Abstract" data-content="Recent face detection methods have achieved high detection rates in unconstrained environments. However, as they still generate excessive false positives, any method for reducing false positives is highly desirable. This work aims to massively reduce false positives of existing face detection methods whilst maintaining the true detection rate. In addition, the proposed method also aims to sidestep the detector retraining task which generally requires enormous effort. To this end, we propose a two-stage framework which cascades two off-the-shelf face detectors. Not all face detectors can be cascaded and achieve good performance. Thus, we study three properties that allow us to determine the best pair of detectors. These three properties are: (1) correlation of true positives; (2) diversity of false positives and (3) detector runtime. Experimental results on recent large benchmark datasets such as FDDB and WIDER FACE support our findings that the false positives of a face detector could be potentially reduced by 90% whilst still maintaining high true positive detection rate. In addition, with a slight decrease in true positives, we found a pair of face detector that achieves significantly lower false positives, while being five times faster than the current state-of-the-art detector."
            >Abstract</a>
            <a class="btn btn-default btn-xs" target="_blank" href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w11/Yang_It_Takes_Two_CVPR_2018_paper.pdf">PDF</a>
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://alan.vision/eccv18_graph">Project</a> -->
            <a class="btn btn-default btn-xs" target="_blank" href="http://siqi.vision/publications/cvprw18_poster.pdf">Poster</a>
			<!-- <a class="btn btn-default btn-xs" target="_blank" href="https://www.youtube.com/watch?v=nJdG4ujAg1Q">Demo video</a> -->
          </div>
        </div>
      </div>
	  
	  <div class="row paper">
        <div class="col-xs-3">
          <img src="publications/tvgan.jpg" class="paper-fig img-responsive">
        </div>
        <div class="col-xs-9">
          <h4 class="text-left">Pyromellitic dianhydride-based polyimide anodes for sodium-ion batteries</h4>
          <p class="text-left">
            <span class="label label-success">Face Recognition</span>
            <span class="label label-success">Generative Adversarial Network</span>
            <!-- <span class="label label-success">Object Detection</span> -->
<!--             <span class="label label-success">Learning Using Priviledged Information</span> -->
          </p>
          <p class="text-left">Teng Zhang, <strong>Siqi Yang</strong>, Arnold Wiliem, Brian C. Lovell</p>
          <p class="text-left">Electrochim. Acta, 2018, 265, 702-708.</p>
          <div class="text-left btns">
            <a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
               title="Abstract" data-content="This work tackles the face recognition task on images captured using thermal camera sensors which can operate in the non-light environment. While it can greatly increase the scope and benefits of the current security surveillance systems, performing such a task using thermal images is a challenging problem compared to face recognition task in the Visible Light Domain (VLD). This is partly due to the significantly smaller amount of thermal imagery data collected compared to the VLD data. Unfortunately, direct application of the existing very strong face recognition models trained using VLD data into the thermal imagery data will not produce a satisfactory performance. This is due to the existence of the domain gap between the thermal and VLD images. To this end, we propose a Thermal-to-Visible Generative Adversarial Network (TV-GAN) that is able to transform thermal face images into their corresponding VLD images whilst maintaining identity information which is sufficient enough for the existing VLD face recognition models to perform recognition. Some examples are presented in Figure 1. Unlike the previous methods, our proposed TV-GAN uses an explicit closed-set face recognition loss to regularize the discriminator network training. This information will then be conveyed into the generator network in the form of gradient loss. In the experiment, we show that by using this additional explicit regularization for the discriminator network, the TV-GAN is able to preserve more identity information when translating a thermal image of a person which is not seen before by the TV-GAN."
            >Abstract</a>
            <a class="btn btn-default btn-xs" target="_blank" href="https://arxiv.org/abs/1712.02514">PDF</a>
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://alan.vision/eccv18_graph">Project</a> -->
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://siqi.vision/publications/cvprw18_poster.pdf">Poster</a> -->
			<!-- <a class="btn btn-default btn-xs" target="_blank" href="https://www.youtube.com/watch?v=nJdG4ujAg1Q">Demo video</a> -->
          </div>
        </div>
      </div>
	  
	  <div class="row paper">
        <div class="col-xs-3">
          <img src="publications/ihog-01.jpg" class="paper-fig img-responsive">
        </div>
        <div class="col-xs-9">
          <h4 class="text-left">To Face or Not To Face: Towards Reducing False Positive of Face Detection</h4>
          <p class="text-left">
            <span class="label label-success">Face Detection</span>
            <span class="label label-success">False Positive Analysis</span>
            <!-- <span class="label label-success">Object Detection</span> -->
<!--             <span class="label label-success">Learning Using Priviledged Information</span> -->
          </p>
          <p class="text-left"><strong>Siqi Yang</strong>, Arnold Wiliem, Brian C. Lovell</p>
          <p class="text-left">Image and Vision Computing New Zealand (IVCNZ), 2016</p>
          <div class="text-left btns">
            <a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
               title="Abstract" data-content="We tackle the problem of reducing the false positive rate of face detectors by applying a classifier after the detection step. We first define and study this post classification problem. To this end, we first consider the multiple-stage cascade structure which is the most common face detection architecture. Here, each cascade stage aims to solve a binary classification problem, denoted the Face/non-Face (FnF) problem. In this context, the post classification problem can be considered as the most challenging FnF problem, or the Hard FnF (HFnF) problem. To study the HFnF problem, we propose HFnF datasets derived from the recent face detection datasets. A baseline method utilizing the GIST features and Support Vector Machine (SVM) classifier is also proposed. In our evaluation, we found that it is possible to further improve the face detection performance by addressing the HFnF problem."
            >Abstract</a>
            <a class="btn btn-default btn-xs" target="_blank" href="https://ieeexplore.ieee.org/abstract/document/7804415">PDF</a>
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://alan.vision/eccv18_graph">Project</a> -->
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://siqi.vision/publications/cvprw18_poster.pdf">Poster</a> -->
			<!-- <a class="btn btn-default btn-xs" target="_blank" href="https://www.youtube.com/watch?v=nJdG4ujAg1Q">Demo video</a> -->
          </div>
        </div>
      </div>
	  
	  <div class="row paper">
        <div class="col-xs-3">
          <img src="publications/GistDemo.jpg" class="paper-fig img-responsive">
        </div>
        <div class="col-xs-9">
          <h4 class="text-left">The GIST of Aligning Faces</h4>
          <p class="text-left">
            <span class="label label-success">Face Alignment</span>
            <!-- <span class="label label-success">Generative Adversarial Network</span> -->
            <!-- <span class="label label-success">Object Detection</span> -->
<!--             <span class="label label-success">Learning Using Priviledged Information</span> -->
          </p>
          <p class="text-left"><strong>Siqi Yang</strong>, Arnold Wiliem, Brian C. Lovell</p>
          <p class="text-left">International Conference on Pattern Recognition (ICPR), 2016</p>
          <div class="text-left btns">
            <a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
               title="Abstract" data-content="We propose a novel supervised initialization scheme for cascaded face alignment by searching nearest neighbors based on global image descriptors. Unlike existing schemes which resort to additional large training data sets for learning features, our method does not require additional training steps; thus making our method low computational. Moreover, we found that it is sufficient to use a simple low-dimensional global image descriptor that is easy to extract. In particular, in this work we use the GIST features as our global image descriptor. The proposed initialization scheme outperforms existing initialization schemes for face alignment and improves on the state-of-the-art methods on two challenging datasets, 300-W and COFW."
            >Abstract</a>
            <a class="btn btn-default btn-xs" target="_blank" href="https://ieeexplore.ieee.org/abstract/document/7900095">PDF</a>
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://alan.vision/eccv18_graph">Project</a> -->
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://siqi.vision/publications/cvprw18_poster.pdf">Poster</a> -->
			<!-- <a class="btn btn-default btn-xs" target="_blank" href="https://www.youtube.com/watch?v=nJdG4ujAg1Q">Demo video</a> -->
          </div>
        </div>
      </div>
	  
	  <div class="row paper">
        <div class="col-xs-3">
          <img src="publications/emotion.png" class="paper-fig img-responsive">
        </div>
        <div class="col-xs-9">
          <h4 class="text-left">Landmark manifold: Revisiting the Riemannian manifold approach for facial emotion recognition</h4>
          <p class="text-left">
            <span class="label label-success">Facial Emotion Recognition</span>
            <!-- <span class="label label-success">Generative Adversarial Network</span> -->
            <!-- <span class="label label-success">Object Detection</span> -->
<!--             <span class="label label-success">Learning Using Priviledged Information</span> -->
          </p>
          <p class="text-left">Kun Zhao, <strong>Siqi Yang</strong>, Arnold Wiliem, Brian C. Lovell</p>
          <p class="text-left">International Conference on Pattern Recognition (ICPR), 2016</p>
          <div class="text-left btns">
            <a tabindex="0" class="btn btn-default btn-xs" role="button" data-toggle="popover" data-trigger="hover" data-placement="right"
               title="Abstract" data-content="Automatically recognising facial emotions has drawn increasing attention in computer vision. Facial landmark based methods are one of the most widely used approaches to perform this task. However, these approaches do not provide good performance. Thus, researchers usually tend to combine more information such as textural and audio information to increase the recognition rate. In this paper we propose a novel method, here called the landmark manifold, that shows the possibility to achieve competitive performance by facial landmark information alone. Through experiments on the well-known dataset: marked Cohn-Kanade extended facial emotion dataset (CK+), we show that with accurate facial landmarks, our simple approach is fast to run and can achieve competitive performance with enormously expensive methods."
            >Abstract</a>
            <a class="btn btn-default btn-xs" target="_blank" href="https://ieeexplore.ieee.org/abstract/document/7899782">PDF</a>
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://alan.vision/eccv18_graph">Project</a> -->
            <!-- <a class="btn btn-default btn-xs" target="_blank" href="http://siqi.vision/publications/cvprw18_poster.pdf">Poster</a> -->
			<!-- <a class="btn btn-default btn-xs" target="_blank" href="https://www.youtube.com/watch?v=nJdG4ujAg1Q">Demo video</a> -->
          </div>
        </div>
      </div>
	  

	  
  </div>
</section>	
	
	
<!-- Section: More About Me -->
<section id="more about" class="section-about">
  <div class="container">
    <div class="row">
      <h3 class="text-left">More About Me</h1>
    </div>
	
	<div class="row">
      <p class="text-left">
        I like playing badminton, dancing and photograhing.
		
      </p>
	  <p class="text-left">
	    During my undergraduate study, I was the Head of Social Event Team at the Student Union of School of Electronic & Information Engineering, SCUT, 2011-2013. We organzied the welcome events and annual ball for more than 500 students every year.
      </p>
	  <p class="text-left">
	    In the summer of 2012, I was lucky to be a short-term volunteer teacher in a rural region of China. My role was teaching English and dancing. 
	  </p>
	
  </div>
</section>	
	
<!-- <h1>Hello Internet!</h1>
<p>This is a paragraph.</p> -->
<!-- <script>alert('Random Javascript!');</script> -->

<!--Google Analytics-->
<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
    a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
  })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

  ga('create', 'UA-100690611-1', 'auto');
  ga('send', 'pageview');
</script>


<!-- jQuery -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"
        integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Custom JavaScript -->
<script src="js/effects.js"></script>


</body>
</html>